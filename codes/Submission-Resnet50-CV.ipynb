{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nuclear-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import io\n",
    "import base64\n",
    "from genericpath import isfile\n",
    "import hashlib\n",
    "import shutil\n",
    "import itertools\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image, ImageDraw\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from adamp import AdamP\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "import timm\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "excessive-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "from modules.dataset import *\n",
    "from modules.transformation import *\n",
    "from modules.imbalancedsampler import *\n",
    "from modules.loss import *\n",
    "from modules.config import Config as conf\n",
    "from modules.config import HyperParameter as params\n",
    "from modules.inference import *\n",
    "from modules.utils import *\n",
    "from modules.train import *\n",
    "from modules.ensemble import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stretch-microwave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 실험은 seed 2021로 고정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "seed_everything(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-charm",
   "metadata": {},
   "source": [
    "## 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-geography",
   "metadata": {},
   "source": [
    "- age의 기준 中 60세 이상을 58세 이상으로 변경\n",
    "- Stratified K-Fold 적용\n",
    "   - 동일한 사람이 학습/검증 데이터에 모두 들어가있지않기\n",
    "   - 분포가 특정 클래스에 편향되어 있지 않기\n",
    "- transform 적용\n",
    "    - centercrop(224)\n",
    "    - normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "indonesian-scottish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [00:05, 494.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = PreprocessedDataset(conf.train_dir + '/train.csv', False, 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "modular-testimony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm in simple train\n",
      "I'm in simple val\n"
     ]
    }
   ],
   "source": [
    "transform = get_transforms()\n",
    "train_tf, val_tf, test_tf = transform['train'], transform['val'], transform['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-record",
   "metadata": {},
   "source": [
    "- Stratified K-Fold 적용 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "humanitarian-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3780\n",
       "3    3780\n",
       "2    3780\n",
       "1    3780\n",
       "0    3780\n",
       "Name: Fold, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_df['Fold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-childhood",
   "metadata": {},
   "source": [
    "## 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unusual-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= F1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vanilla-canyon",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Done preparing training & validation set\n",
      "Start Training\n",
      "====================================================================================================\n",
      "Epoch[0/5](20/237) || training loss 0.946 || training accuracy 12.19% || lr [1e-05]\n",
      "Epoch[0/5](40/237) || training loss 0.9399 || training accuracy 23.83% || lr [1e-05]\n",
      "Epoch[0/5](60/237) || training loss 0.9283 || training accuracy 34.45% || lr [1e-05]\n",
      "Epoch[0/5](80/237) || training loss 0.9019 || training accuracy 42.50% || lr [1e-05]\n",
      "Epoch[0/5](100/237) || training loss 0.8535 || training accuracy 48.05% || lr [1e-05]\n",
      "Epoch[0/5](120/237) || training loss 0.8056 || training accuracy 51.02% || lr [1e-05]\n",
      "Epoch[0/5](140/237) || training loss 0.755 || training accuracy 57.89% || lr [1e-05]\n",
      "Epoch[0/5](160/237) || training loss 0.7108 || training accuracy 55.08% || lr [1e-05]\n",
      "Epoch[0/5](180/237) || training loss 0.6679 || training accuracy 59.06% || lr [1e-05]\n",
      "Epoch[0/5](200/237) || training loss 0.6419 || training accuracy 61.88% || lr [1e-05]\n",
      "Epoch[0/5](220/237) || training loss 0.5932 || training accuracy 64.92% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 70.85%, loss: 0.78 || best acc : 70.85%, best loss: 0.78\n",
      "Epoch[1/5](20/237) || training loss 0.5192 || training accuracy 66.02% || lr [5e-06]\n",
      "Epoch[1/5](40/237) || training loss 0.5121 || training accuracy 67.34% || lr [5e-06]\n",
      "Epoch[1/5](60/237) || training loss 0.4895 || training accuracy 67.89% || lr [5e-06]\n",
      "Epoch[1/5](80/237) || training loss 0.4751 || training accuracy 67.89% || lr [5e-06]\n",
      "Epoch[1/5](100/237) || training loss 0.4363 || training accuracy 70.86% || lr [5e-06]\n",
      "Epoch[1/5](120/237) || training loss 0.4385 || training accuracy 71.72% || lr [5e-06]\n",
      "Epoch[1/5](140/237) || training loss 0.4123 || training accuracy 76.25% || lr [5e-06]\n",
      "Epoch[1/5](160/237) || training loss 0.4182 || training accuracy 75.62% || lr [5e-06]\n",
      "Epoch[1/5](180/237) || training loss 0.3708 || training accuracy 79.30% || lr [5e-06]\n",
      "Epoch[1/5](200/237) || training loss 0.3693 || training accuracy 79.38% || lr [5e-06]\n",
      "Epoch[1/5](220/237) || training loss 0.3571 || training accuracy 79.69% || lr [5e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 82.31%, loss: 0.69 || best acc : 82.31%, best loss: 0.69\n",
      "Epoch[2/5](20/237) || training loss 0.3308 || training accuracy 82.50% || lr [0.0]\n",
      "Epoch[2/5](40/237) || training loss 0.3323 || training accuracy 81.02% || lr [0.0]\n",
      "Epoch[2/5](60/237) || training loss 0.3477 || training accuracy 80.70% || lr [0.0]\n",
      "Epoch[2/5](80/237) || training loss 0.3327 || training accuracy 82.03% || lr [0.0]\n",
      "Epoch[2/5](100/237) || training loss 0.3562 || training accuracy 80.55% || lr [0.0]\n",
      "Epoch[2/5](120/237) || training loss 0.3525 || training accuracy 78.12% || lr [0.0]\n",
      "Epoch[2/5](140/237) || training loss 0.3657 || training accuracy 80.23% || lr [0.0]\n",
      "Epoch[2/5](160/237) || training loss 0.3307 || training accuracy 81.48% || lr [0.0]\n",
      "Epoch[2/5](180/237) || training loss 0.3285 || training accuracy 83.83% || lr [0.0]\n",
      "Epoch[2/5](200/237) || training loss 0.3497 || training accuracy 80.08% || lr [0.0]\n",
      "Epoch[2/5](220/237) || training loss 0.3554 || training accuracy 79.53% || lr [0.0]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 82.96%, loss: 0.69 || best acc : 82.96%, best loss: 0.69\n",
      "Epoch[3/5](20/237) || training loss 0.3667 || training accuracy 78.91% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](40/237) || training loss 0.3281 || training accuracy 81.64% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](60/237) || training loss 0.3251 || training accuracy 81.41% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](80/237) || training loss 0.3167 || training accuracy 81.17% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](100/237) || training loss 0.2827 || training accuracy 83.36% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](120/237) || training loss 0.258 || training accuracy 86.80% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](140/237) || training loss 0.2652 || training accuracy 85.00% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](160/237) || training loss 0.2728 || training accuracy 84.69% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](180/237) || training loss 0.2663 || training accuracy 84.14% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](200/237) || training loss 0.2431 || training accuracy 85.31% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](220/237) || training loss 0.2511 || training accuracy 83.98% || lr [4.9999999999999996e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 85.81%, loss: 0.64 || best acc : 85.81%, best loss: 0.64\n",
      "Epoch[4/5](20/237) || training loss 0.2289 || training accuracy 85.55% || lr [1e-05]\n",
      "Epoch[4/5](40/237) || training loss 0.2165 || training accuracy 87.97% || lr [1e-05]\n",
      "Epoch[4/5](60/237) || training loss 0.2274 || training accuracy 86.80% || lr [1e-05]\n",
      "Epoch[4/5](80/237) || training loss 0.2084 || training accuracy 88.75% || lr [1e-05]\n",
      "Epoch[4/5](100/237) || training loss 0.1858 || training accuracy 88.83% || lr [1e-05]\n",
      "Epoch[4/5](120/237) || training loss 0.1702 || training accuracy 89.61% || lr [1e-05]\n",
      "Epoch[4/5](140/237) || training loss 0.1806 || training accuracy 89.84% || lr [1e-05]\n",
      "Epoch[4/5](160/237) || training loss 0.1636 || training accuracy 90.47% || lr [1e-05]\n",
      "Epoch[4/5](180/237) || training loss 0.152 || training accuracy 90.47% || lr [1e-05]\n",
      "Epoch[4/5](200/237) || training loss 0.1438 || training accuracy 91.80% || lr [1e-05]\n",
      "Epoch[4/5](220/237) || training loss 0.1504 || training accuracy 92.19% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 90.60%, loss:  0.6 || best acc : 90.60%, best loss:  0.6\n",
      "====================================================================================================\n",
      "fold: 0, time: 0:08:24\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [08:24<33:37, 504.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Done preparing training & validation set\n",
      "Start Training\n",
      "====================================================================================================\n",
      "Epoch[0/5](20/237) || training loss 0.9466 || training accuracy 10.78% || lr [1e-05]\n",
      "Epoch[0/5](40/237) || training loss 0.9403 || training accuracy 26.41% || lr [1e-05]\n",
      "Epoch[0/5](60/237) || training loss 0.9266 || training accuracy 44.22% || lr [1e-05]\n",
      "Epoch[0/5](80/237) || training loss 0.8977 || training accuracy 50.39% || lr [1e-05]\n",
      "Epoch[0/5](100/237) || training loss 0.8493 || training accuracy 53.83% || lr [1e-05]\n",
      "Epoch[0/5](120/237) || training loss 0.799 || training accuracy 57.03% || lr [1e-05]\n",
      "Epoch[0/5](140/237) || training loss 0.747 || training accuracy 61.41% || lr [1e-05]\n",
      "Epoch[0/5](160/237) || training loss 0.6884 || training accuracy 60.78% || lr [1e-05]\n",
      "Epoch[0/5](180/237) || training loss 0.6431 || training accuracy 63.83% || lr [1e-05]\n",
      "Epoch[0/5](200/237) || training loss 0.6036 || training accuracy 65.39% || lr [1e-05]\n",
      "Epoch[0/5](220/237) || training loss 0.5528 || training accuracy 68.67% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 66.56%, loss: 0.78 || best acc : 66.56%, best loss: 0.78\n",
      "Epoch[1/5](20/237) || training loss 0.4958 || training accuracy 69.06% || lr [5e-06]\n",
      "Epoch[1/5](40/237) || training loss 0.4682 || training accuracy 72.11% || lr [5e-06]\n",
      "Epoch[1/5](60/237) || training loss 0.4514 || training accuracy 73.05% || lr [5e-06]\n",
      "Epoch[1/5](80/237) || training loss 0.4335 || training accuracy 72.73% || lr [5e-06]\n",
      "Epoch[1/5](100/237) || training loss 0.4316 || training accuracy 71.80% || lr [5e-06]\n",
      "Epoch[1/5](120/237) || training loss 0.4103 || training accuracy 74.61% || lr [5e-06]\n",
      "Epoch[1/5](140/237) || training loss 0.3927 || training accuracy 75.31% || lr [5e-06]\n",
      "Epoch[1/5](160/237) || training loss 0.3746 || training accuracy 77.81% || lr [5e-06]\n",
      "Epoch[1/5](180/237) || training loss 0.3675 || training accuracy 77.11% || lr [5e-06]\n",
      "Epoch[1/5](200/237) || training loss 0.3559 || training accuracy 78.98% || lr [5e-06]\n",
      "Epoch[1/5](220/237) || training loss 0.3348 || training accuracy 80.62% || lr [5e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 80.26%, loss: 0.69 || best acc : 80.26%, best loss: 0.69\n",
      "Epoch[2/5](20/237) || training loss 0.3256 || training accuracy 80.70% || lr [0.0]\n",
      "Epoch[2/5](40/237) || training loss 0.3266 || training accuracy 81.88% || lr [0.0]\n",
      "Epoch[2/5](60/237) || training loss 0.3013 || training accuracy 83.67% || lr [0.0]\n",
      "Epoch[2/5](80/237) || training loss 0.3287 || training accuracy 81.88% || lr [0.0]\n",
      "Epoch[2/5](100/237) || training loss 0.3196 || training accuracy 80.31% || lr [0.0]\n",
      "Epoch[2/5](120/237) || training loss 0.311 || training accuracy 82.58% || lr [0.0]\n",
      "Epoch[2/5](140/237) || training loss 0.3299 || training accuracy 80.62% || lr [0.0]\n",
      "Epoch[2/5](160/237) || training loss 0.3257 || training accuracy 81.02% || lr [0.0]\n",
      "Epoch[2/5](180/237) || training loss 0.3135 || training accuracy 81.95% || lr [0.0]\n",
      "Epoch[2/5](200/237) || training loss 0.3148 || training accuracy 82.97% || lr [0.0]\n",
      "Epoch[2/5](220/237) || training loss 0.319 || training accuracy 80.86% || lr [0.0]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 80.54%, loss: 0.69 || best acc : 80.54%, best loss: 0.69\n",
      "Epoch[3/5](20/237) || training loss 0.3172 || training accuracy 81.41% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](40/237) || training loss 0.3149 || training accuracy 82.27% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](60/237) || training loss 0.2884 || training accuracy 84.53% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](80/237) || training loss 0.2752 || training accuracy 85.16% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](100/237) || training loss 0.2567 || training accuracy 85.78% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](120/237) || training loss 0.2634 || training accuracy 84.45% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](140/237) || training loss 0.2554 || training accuracy 85.00% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](160/237) || training loss 0.2446 || training accuracy 85.47% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](180/237) || training loss 0.235 || training accuracy 86.64% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](200/237) || training loss 0.244 || training accuracy 86.17% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](220/237) || training loss 0.2283 || training accuracy 85.94% || lr [4.9999999999999996e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 87.76%, loss: 0.63 || best acc : 87.76%, best loss: 0.63\n",
      "Epoch[4/5](20/237) || training loss 0.2225 || training accuracy 87.66% || lr [1e-05]\n",
      "Epoch[4/5](40/237) || training loss 0.2241 || training accuracy 87.34% || lr [1e-05]\n",
      "Epoch[4/5](60/237) || training loss 0.2016 || training accuracy 87.97% || lr [1e-05]\n",
      "Epoch[4/5](80/237) || training loss 0.1786 || training accuracy 89.84% || lr [1e-05]\n",
      "Epoch[4/5](100/237) || training loss 0.1873 || training accuracy 88.36% || lr [1e-05]\n",
      "Epoch[4/5](120/237) || training loss 0.1665 || training accuracy 90.23% || lr [1e-05]\n",
      "Epoch[4/5](140/237) || training loss 0.1653 || training accuracy 89.84% || lr [1e-05]\n",
      "Epoch[4/5](160/237) || training loss 0.1543 || training accuracy 91.56% || lr [1e-05]\n",
      "Epoch[4/5](180/237) || training loss 0.1631 || training accuracy 90.23% || lr [1e-05]\n",
      "Epoch[4/5](200/237) || training loss 0.165 || training accuracy 89.84% || lr [1e-05]\n",
      "Epoch[4/5](220/237) || training loss 0.1403 || training accuracy 91.56% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 91.67%, loss: 0.59 || best acc : 91.67%, best loss: 0.59\n",
      "====================================================================================================\n",
      "fold: 1, time: 0:07:58\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [16:23<24:50, 496.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Done preparing training & validation set\n",
      "Start Training\n",
      "====================================================================================================\n",
      "Epoch[0/5](20/237) || training loss 0.9453 || training accuracy 13.20% || lr [1e-05]\n",
      "Epoch[0/5](40/237) || training loss 0.9384 || training accuracy 30.47% || lr [1e-05]\n",
      "Epoch[0/5](60/237) || training loss 0.9282 || training accuracy 41.09% || lr [1e-05]\n",
      "Epoch[0/5](80/237) || training loss 0.9004 || training accuracy 50.86% || lr [1e-05]\n",
      "Epoch[0/5](100/237) || training loss 0.851 || training accuracy 52.50% || lr [1e-05]\n",
      "Epoch[0/5](120/237) || training loss 0.7923 || training accuracy 53.05% || lr [1e-05]\n",
      "Epoch[0/5](140/237) || training loss 0.7427 || training accuracy 55.31% || lr [1e-05]\n",
      "Epoch[0/5](160/237) || training loss 0.6791 || training accuracy 59.45% || lr [1e-05]\n",
      "Epoch[0/5](180/237) || training loss 0.6355 || training accuracy 64.69% || lr [1e-05]\n",
      "Epoch[0/5](200/237) || training loss 0.5954 || training accuracy 66.25% || lr [1e-05]\n",
      "Epoch[0/5](220/237) || training loss 0.5405 || training accuracy 70.70% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 73.58%, loss: 0.77 || best acc : 73.58%, best loss: 0.77\n",
      "Epoch[1/5](20/237) || training loss 0.4865 || training accuracy 74.38% || lr [5e-06]\n",
      "Epoch[1/5](40/237) || training loss 0.4756 || training accuracy 72.27% || lr [5e-06]\n",
      "Epoch[1/5](60/237) || training loss 0.4513 || training accuracy 75.94% || lr [5e-06]\n",
      "Epoch[1/5](80/237) || training loss 0.4214 || training accuracy 75.47% || lr [5e-06]\n",
      "Epoch[1/5](100/237) || training loss 0.4131 || training accuracy 77.27% || lr [5e-06]\n",
      "Epoch[1/5](120/237) || training loss 0.4081 || training accuracy 74.22% || lr [5e-06]\n",
      "Epoch[1/5](140/237) || training loss 0.3796 || training accuracy 78.75% || lr [5e-06]\n",
      "Epoch[1/5](160/237) || training loss 0.3505 || training accuracy 80.47% || lr [5e-06]\n",
      "Epoch[1/5](180/237) || training loss 0.3418 || training accuracy 81.56% || lr [5e-06]\n",
      "Epoch[1/5](200/237) || training loss 0.3357 || training accuracy 81.25% || lr [5e-06]\n",
      "Epoch[1/5](220/237) || training loss 0.3295 || training accuracy 80.86% || lr [5e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 81.85%, loss: 0.68 || best acc : 81.85%, best loss: 0.68\n",
      "Epoch[2/5](20/237) || training loss 0.3049 || training accuracy 83.44% || lr [0.0]\n",
      "Epoch[2/5](40/237) || training loss 0.2922 || training accuracy 84.61% || lr [0.0]\n",
      "Epoch[2/5](60/237) || training loss 0.3046 || training accuracy 81.88% || lr [0.0]\n",
      "Epoch[2/5](80/237) || training loss 0.2893 || training accuracy 83.98% || lr [0.0]\n",
      "Epoch[2/5](100/237) || training loss 0.3047 || training accuracy 84.30% || lr [0.0]\n",
      "Epoch[2/5](120/237) || training loss 0.3076 || training accuracy 81.64% || lr [0.0]\n",
      "Epoch[2/5](140/237) || training loss 0.3164 || training accuracy 81.41% || lr [0.0]\n",
      "Epoch[2/5](160/237) || training loss 0.2963 || training accuracy 84.06% || lr [0.0]\n",
      "Epoch[2/5](180/237) || training loss 0.3099 || training accuracy 83.44% || lr [0.0]\n",
      "Epoch[2/5](200/237) || training loss 0.2889 || training accuracy 84.69% || lr [0.0]\n",
      "Epoch[2/5](220/237) || training loss 0.2929 || training accuracy 83.98% || lr [0.0]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 82.66%, loss: 0.68 || best acc : 82.66%, best loss: 0.68\n",
      "Epoch[3/5](20/237) || training loss 0.3102 || training accuracy 81.25% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](40/237) || training loss 0.2996 || training accuracy 83.05% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](60/237) || training loss 0.2724 || training accuracy 83.91% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](80/237) || training loss 0.2619 || training accuracy 85.86% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](100/237) || training loss 0.2707 || training accuracy 84.22% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](120/237) || training loss 0.2771 || training accuracy 83.75% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](140/237) || training loss 0.2462 || training accuracy 85.94% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](160/237) || training loss 0.2321 || training accuracy 85.16% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](180/237) || training loss 0.2234 || training accuracy 85.86% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](200/237) || training loss 0.2267 || training accuracy 86.17% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](220/237) || training loss 0.2458 || training accuracy 87.03% || lr [4.9999999999999996e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 86.41%, loss: 0.64 || best acc : 86.41%, best loss: 0.64\n",
      "Epoch[4/5](20/237) || training loss 0.2065 || training accuracy 88.83% || lr [1e-05]\n",
      "Epoch[4/5](40/237) || training loss 0.2261 || training accuracy 86.56% || lr [1e-05]\n",
      "Epoch[4/5](60/237) || training loss 0.1928 || training accuracy 88.05% || lr [1e-05]\n",
      "Epoch[4/5](80/237) || training loss 0.2039 || training accuracy 86.41% || lr [1e-05]\n",
      "Epoch[4/5](100/237) || training loss 0.1862 || training accuracy 88.98% || lr [1e-05]\n",
      "Epoch[4/5](120/237) || training loss 0.1644 || training accuracy 89.92% || lr [1e-05]\n",
      "Epoch[4/5](140/237) || training loss 0.1741 || training accuracy 89.38% || lr [1e-05]\n",
      "Epoch[4/5](160/237) || training loss 0.1675 || training accuracy 90.94% || lr [1e-05]\n",
      "Epoch[4/5](180/237) || training loss 0.1591 || training accuracy 90.31% || lr [1e-05]\n",
      "Epoch[4/5](200/237) || training loss 0.1716 || training accuracy 89.53% || lr [1e-05]\n",
      "Epoch[4/5](220/237) || training loss 0.142 || training accuracy 91.09% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 90.42%, loss:  0.6 || best acc : 90.42%, best loss:  0.6\n",
      "====================================================================================================\n",
      "fold: 2, time: 0:07:40\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [24:04<16:12, 486.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Done preparing training & validation set\n",
      "Start Training\n",
      "====================================================================================================\n",
      "Epoch[0/5](20/237) || training loss 0.9464 || training accuracy 10.00% || lr [1e-05]\n",
      "Epoch[0/5](40/237) || training loss 0.9396 || training accuracy 24.69% || lr [1e-05]\n",
      "Epoch[0/5](60/237) || training loss 0.9294 || training accuracy 38.28% || lr [1e-05]\n",
      "Epoch[0/5](80/237) || training loss 0.9042 || training accuracy 46.64% || lr [1e-05]\n",
      "Epoch[0/5](100/237) || training loss 0.8524 || training accuracy 50.47% || lr [1e-05]\n",
      "Epoch[0/5](120/237) || training loss 0.8028 || training accuracy 51.95% || lr [1e-05]\n",
      "Epoch[0/5](140/237) || training loss 0.7512 || training accuracy 54.37% || lr [1e-05]\n",
      "Epoch[0/5](160/237) || training loss 0.7026 || training accuracy 58.98% || lr [1e-05]\n",
      "Epoch[0/5](180/237) || training loss 0.6679 || training accuracy 58.83% || lr [1e-05]\n",
      "Epoch[0/5](200/237) || training loss 0.6151 || training accuracy 64.22% || lr [1e-05]\n",
      "Epoch[0/5](220/237) || training loss 0.5893 || training accuracy 65.16% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 63.50%, loss: 0.78 || best acc : 63.50%, best loss: 0.78\n",
      "Epoch[1/5](20/237) || training loss 0.5206 || training accuracy 69.38% || lr [5e-06]\n",
      "Epoch[1/5](40/237) || training loss 0.4939 || training accuracy 68.75% || lr [5e-06]\n",
      "Epoch[1/5](60/237) || training loss 0.492 || training accuracy 71.17% || lr [5e-06]\n",
      "Epoch[1/5](80/237) || training loss 0.4545 || training accuracy 73.75% || lr [5e-06]\n",
      "Epoch[1/5](100/237) || training loss 0.4398 || training accuracy 72.73% || lr [5e-06]\n",
      "Epoch[1/5](120/237) || training loss 0.4071 || training accuracy 75.70% || lr [5e-06]\n",
      "Epoch[1/5](140/237) || training loss 0.4139 || training accuracy 76.17% || lr [5e-06]\n",
      "Epoch[1/5](160/237) || training loss 0.3953 || training accuracy 75.86% || lr [5e-06]\n",
      "Epoch[1/5](180/237) || training loss 0.3811 || training accuracy 77.89% || lr [5e-06]\n",
      "Epoch[1/5](200/237) || training loss 0.3557 || training accuracy 80.16% || lr [5e-06]\n",
      "Epoch[1/5](220/237) || training loss 0.3417 || training accuracy 78.52% || lr [5e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 73.80%, loss: 0.69 || best acc : 73.80%, best loss: 0.69\n",
      "Epoch[2/5](20/237) || training loss 0.3396 || training accuracy 80.78% || lr [0.0]\n",
      "Epoch[2/5](40/237) || training loss 0.3561 || training accuracy 77.97% || lr [0.0]\n",
      "Epoch[2/5](60/237) || training loss 0.3533 || training accuracy 80.78% || lr [0.0]\n",
      "Epoch[2/5](80/237) || training loss 0.3237 || training accuracy 79.92% || lr [0.0]\n",
      "Epoch[2/5](100/237) || training loss 0.3301 || training accuracy 81.80% || lr [0.0]\n",
      "Epoch[2/5](120/237) || training loss 0.3442 || training accuracy 78.12% || lr [0.0]\n",
      "Epoch[2/5](140/237) || training loss 0.3327 || training accuracy 82.42% || lr [0.0]\n",
      "Epoch[2/5](160/237) || training loss 0.3351 || training accuracy 80.78% || lr [0.0]\n",
      "Epoch[2/5](180/237) || training loss 0.3454 || training accuracy 78.36% || lr [0.0]\n",
      "Epoch[2/5](200/237) || training loss 0.3445 || training accuracy 78.67% || lr [0.0]\n",
      "Epoch[2/5](220/237) || training loss 0.3331 || training accuracy 78.98% || lr [0.0]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 74.11%, loss: 0.69 || best acc : 74.11%, best loss: 0.69\n",
      "Epoch[3/5](20/237) || training loss 0.3228 || training accuracy 82.19% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](40/237) || training loss 0.3228 || training accuracy 81.25% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](60/237) || training loss 0.3195 || training accuracy 81.95% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](80/237) || training loss 0.3047 || training accuracy 83.98% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](100/237) || training loss 0.2992 || training accuracy 83.75% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](120/237) || training loss 0.2649 || training accuracy 84.22% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](140/237) || training loss 0.2816 || training accuracy 84.77% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](160/237) || training loss 0.2743 || training accuracy 83.67% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](180/237) || training loss 0.2599 || training accuracy 86.48% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](200/237) || training loss 0.251 || training accuracy 84.38% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](220/237) || training loss 0.2694 || training accuracy 83.91% || lr [4.9999999999999996e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 85.48%, loss: 0.64 || best acc : 85.48%, best loss: 0.64\n",
      "Epoch[4/5](20/237) || training loss 0.2366 || training accuracy 87.11% || lr [1e-05]\n",
      "Epoch[4/5](40/237) || training loss 0.2247 || training accuracy 86.02% || lr [1e-05]\n",
      "Epoch[4/5](60/237) || training loss 0.2024 || training accuracy 88.59% || lr [1e-05]\n",
      "Epoch[4/5](80/237) || training loss 0.2002 || training accuracy 88.12% || lr [1e-05]\n",
      "Epoch[4/5](100/237) || training loss 0.1848 || training accuracy 88.20% || lr [1e-05]\n",
      "Epoch[4/5](120/237) || training loss 0.1918 || training accuracy 87.73% || lr [1e-05]\n",
      "Epoch[4/5](140/237) || training loss 0.1934 || training accuracy 87.19% || lr [1e-05]\n",
      "Epoch[4/5](160/237) || training loss 0.1864 || training accuracy 88.52% || lr [1e-05]\n",
      "Epoch[4/5](180/237) || training loss 0.1633 || training accuracy 89.92% || lr [1e-05]\n",
      "Epoch[4/5](200/237) || training loss 0.1579 || training accuracy 90.86% || lr [1e-05]\n",
      "Epoch[4/5](220/237) || training loss 0.1883 || training accuracy 88.98% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 89.78%, loss:  0.6 || best acc : 89.78%, best loss:  0.6\n",
      "====================================================================================================\n",
      "fold: 3, time: 0:07:42\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [31:47<07:59, 479.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Done preparing training & validation set\n",
      "Start Training\n",
      "====================================================================================================\n",
      "Epoch[0/5](20/237) || training loss 0.947 || training accuracy 9.06% || lr [1e-05]\n",
      "Epoch[0/5](40/237) || training loss 0.9393 || training accuracy 26.41% || lr [1e-05]\n",
      "Epoch[0/5](60/237) || training loss 0.9267 || training accuracy 37.42% || lr [1e-05]\n",
      "Epoch[0/5](80/237) || training loss 0.9011 || training accuracy 39.92% || lr [1e-05]\n",
      "Epoch[0/5](100/237) || training loss 0.8617 || training accuracy 40.00% || lr [1e-05]\n",
      "Epoch[0/5](120/237) || training loss 0.8069 || training accuracy 44.06% || lr [1e-05]\n",
      "Epoch[0/5](140/237) || training loss 0.7507 || training accuracy 47.27% || lr [1e-05]\n",
      "Epoch[0/5](160/237) || training loss 0.713 || training accuracy 49.61% || lr [1e-05]\n",
      "Epoch[0/5](180/237) || training loss 0.6777 || training accuracy 54.77% || lr [1e-05]\n",
      "Epoch[0/5](200/237) || training loss 0.6387 || training accuracy 60.23% || lr [1e-05]\n",
      "Epoch[0/5](220/237) || training loss 0.5941 || training accuracy 61.48% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 63.90%, loss: 0.78 || best acc : 63.90%, best loss: 0.78\n",
      "Epoch[1/5](20/237) || training loss 0.5191 || training accuracy 69.22% || lr [5e-06]\n",
      "Epoch[1/5](40/237) || training loss 0.5028 || training accuracy 69.69% || lr [5e-06]\n",
      "Epoch[1/5](60/237) || training loss 0.4902 || training accuracy 68.75% || lr [5e-06]\n",
      "Epoch[1/5](80/237) || training loss 0.4649 || training accuracy 72.11% || lr [5e-06]\n",
      "Epoch[1/5](100/237) || training loss 0.4645 || training accuracy 70.70% || lr [5e-06]\n",
      "Epoch[1/5](120/237) || training loss 0.4347 || training accuracy 72.19% || lr [5e-06]\n",
      "Epoch[1/5](140/237) || training loss 0.4084 || training accuracy 76.25% || lr [5e-06]\n",
      "Epoch[1/5](160/237) || training loss 0.4168 || training accuracy 72.97% || lr [5e-06]\n",
      "Epoch[1/5](180/237) || training loss 0.3886 || training accuracy 79.14% || lr [5e-06]\n",
      "Epoch[1/5](200/237) || training loss 0.3541 || training accuracy 79.30% || lr [5e-06]\n",
      "Epoch[1/5](220/237) || training loss 0.3523 || training accuracy 81.09% || lr [5e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 80.05%, loss: 0.68 || best acc : 80.05%, best loss: 0.68\n",
      "Epoch[2/5](20/237) || training loss 0.3248 || training accuracy 81.25% || lr [0.0]\n",
      "Epoch[2/5](40/237) || training loss 0.343 || training accuracy 79.45% || lr [0.0]\n",
      "Epoch[2/5](60/237) || training loss 0.3452 || training accuracy 78.91% || lr [0.0]\n",
      "Epoch[2/5](80/237) || training loss 0.3232 || training accuracy 81.56% || lr [0.0]\n",
      "Epoch[2/5](100/237) || training loss 0.3275 || training accuracy 81.80% || lr [0.0]\n",
      "Epoch[2/5](120/237) || training loss 0.3344 || training accuracy 81.56% || lr [0.0]\n",
      "Epoch[2/5](140/237) || training loss 0.332 || training accuracy 80.23% || lr [0.0]\n",
      "Epoch[2/5](160/237) || training loss 0.3386 || training accuracy 81.88% || lr [0.0]\n",
      "Epoch[2/5](180/237) || training loss 0.3372 || training accuracy 83.59% || lr [0.0]\n",
      "Epoch[2/5](200/237) || training loss 0.3279 || training accuracy 80.23% || lr [0.0]\n",
      "Epoch[2/5](220/237) || training loss 0.3295 || training accuracy 83.52% || lr [0.0]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 79.99%, loss: 0.68 || best acc : 79.99%, best loss: 0.68\n",
      "Epoch[3/5](20/237) || training loss 0.3387 || training accuracy 80.23% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](40/237) || training loss 0.321 || training accuracy 82.81% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](60/237) || training loss 0.319 || training accuracy 82.42% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](80/237) || training loss 0.303 || training accuracy 82.34% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](100/237) || training loss 0.2817 || training accuracy 84.22% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](120/237) || training loss 0.257 || training accuracy 85.00% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](140/237) || training loss 0.2561 || training accuracy 85.86% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](160/237) || training loss 0.2535 || training accuracy 85.70% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](180/237) || training loss 0.2504 || training accuracy 85.47% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](200/237) || training loss 0.2416 || training accuracy 85.70% || lr [4.9999999999999996e-06]\n",
      "Epoch[3/5](220/237) || training loss 0.2265 || training accuracy 87.03% || lr [4.9999999999999996e-06]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 85.22%, loss: 0.63 || best acc : 85.22%, best loss: 0.63\n",
      "Epoch[4/5](20/237) || training loss 0.2211 || training accuracy 86.17% || lr [1e-05]\n",
      "Epoch[4/5](40/237) || training loss 0.205 || training accuracy 87.73% || lr [1e-05]\n",
      "Epoch[4/5](60/237) || training loss 0.2148 || training accuracy 87.89% || lr [1e-05]\n",
      "Epoch[4/5](80/237) || training loss 0.214 || training accuracy 87.42% || lr [1e-05]\n",
      "Epoch[4/5](100/237) || training loss 0.1876 || training accuracy 89.30% || lr [1e-05]\n",
      "Epoch[4/5](120/237) || training loss 0.171 || training accuracy 89.06% || lr [1e-05]\n",
      "Epoch[4/5](140/237) || training loss 0.1817 || training accuracy 88.91% || lr [1e-05]\n",
      "Epoch[4/5](160/237) || training loss 0.1699 || training accuracy 91.02% || lr [1e-05]\n",
      "Epoch[4/5](180/237) || training loss 0.1861 || training accuracy 88.98% || lr [1e-05]\n",
      "Epoch[4/5](200/237) || training loss 0.1711 || training accuracy 90.00% || lr [1e-05]\n",
      "Epoch[4/5](220/237) || training loss 0.1532 || training accuracy 89.84% || lr [1e-05]\n",
      "Calculating validation results...\n",
      "New best model for val accuracy! saving the model..\n",
      "[Val] acc : 87.61%, loss:  0.6 || best acc : 87.61%, best loss:  0.6\n",
      "====================================================================================================\n",
      "fold: 4, time: 0:07:42\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [39:29<00:00, 474.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "DONE\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for fold_idx in tqdm.tqdm(range(conf.n_fold)):\n",
    "    train_dataset = TransformedDataset(dataset, train_tf, fold_idx)\n",
    "    val_dataset = TransformedDataset(dataset, val_tf, fold_idx)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=params.BATCH_SIZE, \n",
    "                              sampler=ImbalancedDatasetSampler(train_dataset),\n",
    "                              num_workers=params.NUM_WORKERS)\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, \n",
    "                            batch_size=params.BATCH_SIZE, \n",
    "                            shuffle=False,\n",
    "                            num_workers=params.NUM_WORKERS)\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    print(\"Done preparing training & validation set\\nStart Training\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    model = timm.create_model('resnet50', pretrained=True, num_classes=18)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        \n",
    "    optimizer = AdamW(model.parameters(), lr=params.lr, weight_decay=5e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=2, eta_min=0.)\n",
    "    \n",
    "    train_and_validate(model, criterion, optimizer, scheduler, train_loader, len(val_dataset), val_loader)\n",
    "\n",
    "    print(\"=\"*100)\n",
    "    print(f\"fold: {fold_idx}, time: \" + sec_to_str(time.time()-start))\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    torch.save(model, open(f\"resnet50_fold_{fold_idx}\", \"wb\"))\n",
    "    start = time.time()\n",
    "    \n",
    "print(\"=\"*100)\n",
    "print(\"DONE\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-westminster",
   "metadata": {},
   "source": [
    "## 3. Inference with K-Fold Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prompt-player",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FoldEnsemble(\n",
       "  (modelA): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "    (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
       "  )\n",
       "  (modelB): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "    (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
       "  )\n",
       "  (modelC): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "    (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
       "  )\n",
       "  (modelD): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "    (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
       "  )\n",
       "  (modelE): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "    (fc): Linear(in_features=2048, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelA = torch.load(open(os.path.join(conf.model_dir, 'resnet50_fold_0'), \"rb\")).to(device)\n",
    "modelB = torch.load(open(os.path.join(conf.model_dir, 'resnet50_fold_1'), \"rb\")).to(device)\n",
    "modelC = torch.load(open(os.path.join(conf.model_dir, 'resnet50_fold_2'), \"rb\")).to(device)\n",
    "modelD = torch.load(open(os.path.join(conf.model_dir, 'resnet50_fold_3'), \"rb\")).to(device)\n",
    "modelE = torch.load(open(os.path.join(conf.model_dir, 'resnet50_fold_4'), \"rb\")).to(device)\n",
    "\n",
    "model = FoldEnsemble(modelA, modelB, modelC, modelD, modelE)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "essential-productivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-PCIE-32GB\n",
      "====================================================================================================\n",
      "Inference Done\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "inference(model, test_tf, 'resnet50.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
